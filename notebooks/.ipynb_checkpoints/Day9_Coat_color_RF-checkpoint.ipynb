{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Throwback: which SNPs are associated with mouse hair color again?\n",
    "\n",
    "Remember the GWAS task, where we investigated which SNPs were significantly associated with the coat color of mice? Machine learning ties in well with this task. We know random forests are useful to determine the importance of different features when classifying samples. We could ask a random forest to predict hair color from genotype data, and then look at what features it considered important while doing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, cross_val_predict\n",
    "from sklearn import metrics as sme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the genotype and color data. Make sure you index the genotype data explicitly by passing `index_col=\"Locus\"` to the csv reader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "genotype = pd.read_csv(\"files/dataS4.txt\", sep=\"\\t\", comment=\"@\", index_col=\"Locus\")\n",
    "colors = pd.read_csv(\"files/phenotype.csv\", index_col=0, names=[\"color\"], na_values='x').dropna()['color']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C57BL/6J    4.0\n",
       "DBA/2J      1.0\n",
       "B6D2F1      4.0\n",
       "D2B6F1      4.0\n",
       "BXD1        1.0\n",
       "BXD2        4.0\n",
       "BXD5        3.0\n",
       "BXD6        3.0\n",
       "BXD8        3.0\n",
       "BXD9        1.0\n",
       "BXD11       4.0\n",
       "BXD12       3.0\n",
       "BXD13       2.0\n",
       "BXD14       4.0\n",
       "BXD15       2.0\n",
       "BXD16       3.0\n",
       "BXD18       3.0\n",
       "BXD19       3.0\n",
       "BXD20       4.0\n",
       "BXD21       1.0\n",
       "BXD22       3.0\n",
       "BXD23       4.0\n",
       "BXD24       2.0\n",
       "BXD24a      2.0\n",
       "BXD25       2.0\n",
       "BXD27       2.0\n",
       "BXD28       2.0\n",
       "BXD29       3.0\n",
       "BXD30       1.0\n",
       "BXD31       4.0\n",
       "           ... \n",
       "BXD191      4.0\n",
       "BXD192      2.0\n",
       "BXD193      2.0\n",
       "BXD194      2.0\n",
       "BXD195      2.0\n",
       "BXD196      2.0\n",
       "BXD197      2.0\n",
       "BXD198      3.0\n",
       "BXD199      4.0\n",
       "BXD200      2.0\n",
       "BXD201      1.0\n",
       "BXD202      3.0\n",
       "BXD203      2.0\n",
       "BXD204      4.0\n",
       "BXD205      3.0\n",
       "BXD206      1.0\n",
       "BXD207      4.0\n",
       "BXD208      3.0\n",
       "BXD209      2.0\n",
       "BXD210      4.0\n",
       "BXD211      3.0\n",
       "BXD212      3.0\n",
       "BXD213      3.3\n",
       "BXD214      3.5\n",
       "BXD215      3.0\n",
       "BXD216      1.0\n",
       "BXD217      4.0\n",
       "BXD218      4.0\n",
       "BXD219      4.0\n",
       "BXD220      1.0\n",
       "Name: color, Length: 199, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the genotype data into two dataframes: one should contain the metadata (first 3 columns) and the other the actual genotype data. Call them `geno_metadata` and `geno`.\n",
    "\n",
    "Remember, `sklearn` takes samples in rows, and our samples correspond to mice strains here, so transpose `geno`. Also make sure that the indices of the `geno` and `color` DFs line up with each other: only keep the intersection of their indices. Index objects support intersection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "geno_metadata = genotype.iloc[:, :3]\n",
    "geno = genotype.iloc[:,3:].T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 3811)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geno.index.intersection(colors.index)\n",
    "\n",
    "colors = colors.loc[geno.index.intersection(colors.index)]\n",
    "geno = geno.loc[geno.index.intersection(colors.index)]\n",
    "\n",
    "geno.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode the B/D/H/U genotype information with numbers. You can use -1/0/0/1 or 0/1/1/2 for B/H/U/D respectively. Either way, it's best to encode H with a value between B and D since it stands for hybrid.\n",
    "\n",
    "As for encoding colors: they are already numbers. We won't even transform them to the binary black/non-black labels like we did on day 3, we will just feed it them to the predictor as they are. Let the random forest figure out the associations for black/grey/white/brown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 3811)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode = {'B' : 0, 'D' : 2, 'H': 1, 'U' : 1}\n",
    "geno_enc = geno\n",
    "\n",
    "geno_enc = geno_enc.applymap(encode.get)\n",
    "geno_enc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a random forest classifier with all the data. Make sure you use a lot of trees in that forest (a few thousand should be good) so we can get fine-grained values for feature importances. The more decision trees you run the data on, the clearer it gets which features it tests most often."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10000, n_jobs=1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=10000, random_state=0)\n",
    "clf.fit(geno_enc, colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now take the feature importance vector, and add it to the `geno_metadata` DataFrame as a new column. Sort by that column (obviously descending), and look at the most important SNP ids. Compare them with your GWAS data -- no need to load anything, just look at the Manhattan plot from day 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chr</th>\n",
       "      <th>cM</th>\n",
       "      <th>Mb</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Locus</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rs13477796</th>\n",
       "      <td>4</td>\n",
       "      <td>41.281</td>\n",
       "      <td>78.698063</td>\n",
       "      <td>0.013982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rs3708061</th>\n",
       "      <td>4</td>\n",
       "      <td>41.281</td>\n",
       "      <td>80.950126</td>\n",
       "      <td>0.013476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rs13480283</th>\n",
       "      <td>9</td>\n",
       "      <td>45.892</td>\n",
       "      <td>75.877786</td>\n",
       "      <td>0.013142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rs3685573</th>\n",
       "      <td>9</td>\n",
       "      <td>46.179</td>\n",
       "      <td>76.102533</td>\n",
       "      <td>0.012870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rs3658567</th>\n",
       "      <td>4</td>\n",
       "      <td>40.995</td>\n",
       "      <td>76.484833</td>\n",
       "      <td>0.012258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rs3724833</th>\n",
       "      <td>9</td>\n",
       "      <td>45.892</td>\n",
       "      <td>74.735876</td>\n",
       "      <td>0.012120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rs3725904</th>\n",
       "      <td>9</td>\n",
       "      <td>46.179</td>\n",
       "      <td>76.983761</td>\n",
       "      <td>0.011763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rs13480279</th>\n",
       "      <td>9</td>\n",
       "      <td>45.606</td>\n",
       "      <td>74.382952</td>\n",
       "      <td>0.011590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rs3670437</th>\n",
       "      <td>9</td>\n",
       "      <td>45.319</td>\n",
       "      <td>73.954057</td>\n",
       "      <td>0.011244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEL-4_74066970</th>\n",
       "      <td>4</td>\n",
       "      <td>40.708</td>\n",
       "      <td>75.438626</td>\n",
       "      <td>0.010681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rs13477785</th>\n",
       "      <td>4</td>\n",
       "      <td>40.995</td>\n",
       "      <td>75.774916</td>\n",
       "      <td>0.010602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEL-4_74121566</th>\n",
       "      <td>4</td>\n",
       "      <td>40.708</td>\n",
       "      <td>75.493222</td>\n",
       "      <td>0.009829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rs13480277</th>\n",
       "      <td>9</td>\n",
       "      <td>45.319</td>\n",
       "      <td>73.928872</td>\n",
       "      <td>0.009827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rs3674482</th>\n",
       "      <td>9</td>\n",
       "      <td>47.074</td>\n",
       "      <td>77.217283</td>\n",
       "      <td>0.009313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rs13480291</th>\n",
       "      <td>9</td>\n",
       "      <td>47.361</td>\n",
       "      <td>77.779276</td>\n",
       "      <td>0.008695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rs13480276</th>\n",
       "      <td>9</td>\n",
       "      <td>45.033</td>\n",
       "      <td>73.688973</td>\n",
       "      <td>0.008581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rs13480288</th>\n",
       "      <td>9</td>\n",
       "      <td>47.361</td>\n",
       "      <td>77.247378</td>\n",
       "      <td>0.008569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rs6167970</th>\n",
       "      <td>9</td>\n",
       "      <td>45.033</td>\n",
       "      <td>73.368885</td>\n",
       "      <td>0.008431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rs13477804</th>\n",
       "      <td>4</td>\n",
       "      <td>42.501</td>\n",
       "      <td>81.604580</td>\n",
       "      <td>0.008300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEL-4_72665819</th>\n",
       "      <td>4</td>\n",
       "      <td>39.813</td>\n",
       "      <td>74.037476</td>\n",
       "      <td>0.008219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rs13477805</th>\n",
       "      <td>4</td>\n",
       "      <td>42.501</td>\n",
       "      <td>81.934379</td>\n",
       "      <td>0.007840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gnf04.071.066</th>\n",
       "      <td>4</td>\n",
       "      <td>39.813</td>\n",
       "      <td>75.249698</td>\n",
       "      <td>0.007745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gnf09.074.193</th>\n",
       "      <td>9</td>\n",
       "      <td>47.647</td>\n",
       "      <td>79.902981</td>\n",
       "      <td>0.007686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rs6217039</th>\n",
       "      <td>9</td>\n",
       "      <td>47.647</td>\n",
       "      <td>78.046015</td>\n",
       "      <td>0.007649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rs13480302</th>\n",
       "      <td>9</td>\n",
       "      <td>47.937</td>\n",
       "      <td>80.626426</td>\n",
       "      <td>0.006803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rs3674783</th>\n",
       "      <td>4</td>\n",
       "      <td>43.086</td>\n",
       "      <td>83.447453</td>\n",
       "      <td>0.006727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rs4227771</th>\n",
       "      <td>9</td>\n",
       "      <td>43.813</td>\n",
       "      <td>72.952358</td>\n",
       "      <td>0.006555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rs6258088</th>\n",
       "      <td>4</td>\n",
       "      <td>43.086</td>\n",
       "      <td>82.262281</td>\n",
       "      <td>0.006447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rs13477825</th>\n",
       "      <td>4</td>\n",
       "      <td>43.945</td>\n",
       "      <td>87.106964</td>\n",
       "      <td>0.006432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CEL-4_82641197</th>\n",
       "      <td>4</td>\n",
       "      <td>43.372</td>\n",
       "      <td>84.012618</td>\n",
       "      <td>0.006372</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Chr      cM         Mb  importance\n",
       "Locus                                            \n",
       "rs13477796       4  41.281  78.698063    0.013982\n",
       "rs3708061        4  41.281  80.950126    0.013476\n",
       "rs13480283       9  45.892  75.877786    0.013142\n",
       "rs3685573        9  46.179  76.102533    0.012870\n",
       "rs3658567        4  40.995  76.484833    0.012258\n",
       "rs3724833        9  45.892  74.735876    0.012120\n",
       "rs3725904        9  46.179  76.983761    0.011763\n",
       "rs13480279       9  45.606  74.382952    0.011590\n",
       "rs3670437        9  45.319  73.954057    0.011244\n",
       "CEL-4_74066970   4  40.708  75.438626    0.010681\n",
       "rs13477785       4  40.995  75.774916    0.010602\n",
       "CEL-4_74121566   4  40.708  75.493222    0.009829\n",
       "rs13480277       9  45.319  73.928872    0.009827\n",
       "rs3674482        9  47.074  77.217283    0.009313\n",
       "rs13480291       9  47.361  77.779276    0.008695\n",
       "rs13480276       9  45.033  73.688973    0.008581\n",
       "rs13480288       9  47.361  77.247378    0.008569\n",
       "rs6167970        9  45.033  73.368885    0.008431\n",
       "rs13477804       4  42.501  81.604580    0.008300\n",
       "CEL-4_72665819   4  39.813  74.037476    0.008219\n",
       "rs13477805       4  42.501  81.934379    0.007840\n",
       "gnf04.071.066    4  39.813  75.249698    0.007745\n",
       "gnf09.074.193    9  47.647  79.902981    0.007686\n",
       "rs6217039        9  47.647  78.046015    0.007649\n",
       "rs13480302       9  47.937  80.626426    0.006803\n",
       "rs3674783        4  43.086  83.447453    0.006727\n",
       "rs4227771        9  43.813  72.952358    0.006555\n",
       "rs6258088        4  43.086  82.262281    0.006447\n",
       "rs13477825       4  43.945  87.106964    0.006432\n",
       "CEL-4_82641197   4  43.372  84.012618    0.006372"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances = pd.Series(clf.feature_importances_ , index = geno_metadata.index)\n",
    "geno_metadata['importance'] = importances\n",
    "\n",
    "geno_metadata_sorted = geno_metadata.sort_values('importance', ascending=False)\n",
    "geno_metadata_sorted.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is mentionable that all the important features, or at least the 30 most important ones, are located either on chromosom 4 or on chromosome 9. This is interesting, since if we look at the Manhatten plot of Day 3, then those were also the two most significant chromosoms for differential expression. So it seems like the results are correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you took the effort to load that mouse genotype and color data, you might as well take a peek at the performance of the predictor. Calculate a cross-validated accuracy score, and create a confusion matrix for the four colors. You can lower the number of trees used by an order of magnitude, since cross-validation makes things more time intensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[29,  3,  3,  0],\n",
       "       [ 1, 20,  0,  3],\n",
       "       [ 0,  0, 12,  1],\n",
       "       [ 0,  0,  3, 15]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_sparse = RandomForestClassifier(n_estimators= 100)\n",
    "\n",
    "t = cross_val_predict(clf_sparse, geno_enc, colors, cv = StratifiedKFold(3, shuffle=True))\n",
    "\n",
    "sme.confusion_matrix(t, colors)\n",
    "# Numbers are tn, fp, fn, tp for each label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, create a ROC diagram. You know how to make them for binary classifiers... but this isn't a binary classification task. What should it look like when you have 4 labels instead of just 2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_probs = cross_val_predict(clf_sparse, geno_enc, colors, cv = StratifiedKFold(3, shuffle=True), method = 'predict_proba').T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplots(figsize=(16,8))\n",
    "for c, s in enumerate(cv_probs):\n",
    "    fpr, tpr, thresholds = sme.roc_curve(colors==c+1, s)\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label = c)\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A seperate FPR/TPR curve is plotted for each label, so one can see the respective sensitivite and specificity values, but still compare them easily."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
